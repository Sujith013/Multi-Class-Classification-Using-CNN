{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow tensorflow-gpu opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing unclear images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'augmented' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crab', 'dolphin', 'seaturtle', 'starfish']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crab\n",
      "dolphin\n",
      "seaturtle\n",
      "starfish\n"
     ]
    }
   ],
   "source": [
    "for image_class in os.listdir(data_dir): \n",
    "    print(image_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir): \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try: \n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20152 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns value between 0 and 1\n",
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test\n",
    "\n",
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n",
      "126\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "print(train_size)\n",
    "print(val_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add convolution and max-pooling layer\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 127, 127, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 62, 62, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 60, 60, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 30, 30, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 14400)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               3686656   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,697,396\n",
      "Trainable params: 3,697,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "441/441 [==============================] - 376s 849ms/step - loss: 0.5683 - accuracy: 0.7713 - val_loss: 0.0968 - val_accuracy: 0.9779\n",
      "Epoch 2/20\n",
      "441/441 [==============================] - 434s 983ms/step - loss: 0.1233 - accuracy: 0.9653 - val_loss: 0.0721 - val_accuracy: 0.9750\n",
      "Epoch 3/20\n",
      "441/441 [==============================] - 556s 1s/step - loss: 0.0894 - accuracy: 0.9822 - val_loss: 0.0356 - val_accuracy: 0.9906\n",
      "Epoch 4/20\n",
      "441/441 [==============================] - 503s 1s/step - loss: 0.0689 - accuracy: 0.9887 - val_loss: 0.2388 - val_accuracy: 0.9340\n",
      "Epoch 5/20\n",
      "441/441 [==============================] - 481s 1s/step - loss: 0.0597 - accuracy: 0.9897 - val_loss: 0.0312 - val_accuracy: 0.9923\n",
      "Epoch 6/20\n",
      "441/441 [==============================] - 474s 1s/step - loss: 0.0480 - accuracy: 0.9931 - val_loss: 0.0281 - val_accuracy: 0.9955\n",
      "Epoch 7/20\n",
      "441/441 [==============================] - 511s 1s/step - loss: 0.0882 - accuracy: 0.9889 - val_loss: 0.0185 - val_accuracy: 0.9970\n",
      "Epoch 8/20\n",
      "441/441 [==============================] - 446s 1s/step - loss: 0.0507 - accuracy: 0.9936 - val_loss: 0.0792 - val_accuracy: 0.9864\n",
      "Epoch 9/20\n",
      "441/441 [==============================] - 510s 1s/step - loss: 0.0589 - accuracy: 0.9948 - val_loss: 0.0147 - val_accuracy: 0.9965\n",
      "Epoch 10/20\n",
      "441/441 [==============================] - 640s 1s/step - loss: 0.0206 - accuracy: 0.9970 - val_loss: 0.5223 - val_accuracy: 0.9469\n",
      "Epoch 11/20\n",
      "441/441 [==============================] - 407s 922ms/step - loss: 0.0586 - accuracy: 0.9931 - val_loss: 0.0035 - val_accuracy: 0.9983\n",
      "Epoch 12/20\n",
      "441/441 [==============================] - 351s 797ms/step - loss: 0.0191 - accuracy: 0.9972 - val_loss: 1.0267 - val_accuracy: 0.9097\n",
      "Epoch 13/20\n",
      "441/441 [==============================] - 332s 752ms/step - loss: 0.0525 - accuracy: 0.9962 - val_loss: 0.0097 - val_accuracy: 0.9975\n",
      "Epoch 14/20\n",
      "441/441 [==============================] - 327s 740ms/step - loss: 0.0319 - accuracy: 0.9970 - val_loss: 0.0129 - val_accuracy: 0.9975\n",
      "Epoch 15/20\n",
      "441/441 [==============================] - 323s 732ms/step - loss: 0.0370 - accuracy: 0.9962 - val_loss: 0.0935 - val_accuracy: 0.9836\n",
      "Epoch 16/20\n",
      "441/441 [==============================] - 330s 747ms/step - loss: 0.0445 - accuracy: 0.9957 - val_loss: 0.0283 - val_accuracy: 0.9960\n",
      "Epoch 17/20\n",
      "441/441 [==============================] - 348s 788ms/step - loss: 0.0327 - accuracy: 0.9965 - val_loss: 0.0199 - val_accuracy: 0.9975\n",
      "Epoch 18/20\n",
      "441/441 [==============================] - 322s 731ms/step - loss: 0.0441 - accuracy: 0.9971 - val_loss: 0.0206 - val_accuracy: 0.9975\n",
      "Epoch 19/20\n",
      "441/441 [==============================] - 335s 759ms/step - loss: 0.0532 - accuracy: 0.9956 - val_loss: 0.0279 - val_accuracy: 0.9973\n",
      "Epoch 20/20\n",
      "441/441 [==============================] - 323s 731ms/step - loss: 0.0722 - accuracy: 0.9965 - val_loss: 0.0172 - val_accuracy: 0.9973\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#\n",
    "#plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "#plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "#\n",
    "#fig.suptitle('Loss', fontsize=20)\n",
    "#\n",
    "#plt.legend(loc=\"upper right\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#\n",
    "#plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "#plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "#\n",
    "#fig.suptitle('Accuracy', fontsize=20)\n",
    "#\n",
    "#plt.legend(loc=\"lower right\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 225ms/step\n",
      "[3 3 2 2 1 1 2 0 2 1 1 3 0 2 0 2 2 1 0 2 1 1 0 2 1 3 2 1 0 3 1 2]\n",
      "[3, 3, 2, 2, 1, 1, 2, 0, 2, 1, 1, 3, 0, 2, 0, 2, 2, 1, 0, 2, 1, 1, 0, 2, 1, 3, 2, 1, 0, 3, 1, 2]\n",
      "1.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'update_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m pre\u001b[39m.\u001b[39mupdate_state(y, cmp)\n\u001b[0;32m     18\u001b[0m re\u001b[39m.\u001b[39mupdate_state(y, cmp)\n\u001b[1;32m---> 19\u001b[0m acc\u001b[39m.\u001b[39;49mupdate_state(y, cmp)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'update_state'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "for batch in test.as_numpy_iterator():\n",
    "    cmp = [] \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "\n",
    "    for j in range(len(yhat)):\n",
    "        cmp.append(np.argmax(yhat[j]))\n",
    "    \n",
    "    print(y)\n",
    "    print(cmp)\n",
    "\n",
    "    print(r2_score(y,cmp))\n",
    "\n",
    "    pre.update_state(y, cmp)\n",
    "    re.update_state(y, cmp)\n",
    "    acc.update_state(y, cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 1.0\n",
      "Recall : 1.0\n",
      "accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"precision : {pre.result().numpy()}\")\n",
    "print(f\"Recall : {re.result().numpy()}\")\n",
    "print(f\"accuracy : {acc.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread('data/seaturtle/image_300.jpeg')\n",
    "#plt.imshow(img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize = tf.image.resize(img, (256,256))\n",
    "#plt.imshow(resize.numpy().astype(int))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yhat = yhat.round()\n",
    "#pval = np.argmax(yhat)\n",
    "\n",
    "#print(yhat)\n",
    "#print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if(pval == 0): \n",
    "#    print(f'Predicted class is {catgry[0]}')\n",
    "#elif(pval == 1):\n",
    "#    print(f'Predicted class is {catgry[1]}')\n",
    "#elif(pval == 2):\n",
    "#    print(f'Predicted class is {catgry[2]}')\n",
    "#elif(pval == 3):\n",
    "#    print(f'Predicted class is {catgry[3]}')\n",
    "#elif(pval == 4):\n",
    "#    print(f'Predicted class is {catgry[4]}')\n",
    "#elif(pval == 5):\n",
    "#    print(f'Predicted class is {catgry[5]}')\n",
    "#elif(pval == 6):\n",
    "#    print(f'Predicted class is {catgry[6]}')\n",
    "#elif(pval == 7):\n",
    "#    print(f'Predicted class is {catgry[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','imageclassifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.join('models','imageclassifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "71f6c63340f562ab350e69d82cce97e48d9e9c6f1b0042b0ad851aac87d861d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
